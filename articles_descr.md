**Название статьи:** How to solve 90% of NLP problems: a step-by-step guide

**Ссылка:**https://blog.insightdatascience.com/how-to-solve-90-of-nlp-problems-a-step-by-step-guide-fda605278e4e

**Короткое резюме:**
В статье приведена технология решения задач анализа текстов.
Поэтапно:
- Чистим данные: убираем мусорные знаки (делать это можно с помощью регулярных выражений), токенизируем (разделяем на слова), убираем стоп-слова, лемматизируем (приводим каждое слово к начальной форме), меняем все прописные буквы на строчные, исправляем ошибки и опечатки.
- Рассматриваем разные виды представления данных (в общем случае: отбираем признаки). Подходы для текстов: bag-of-words(веса у всех слов одинаковые), tf-idf(веса подбираются в зависимости от частоты встречаемости слова в тексте и документов со словом в коллекции), word2vec(учитывает семантическую связь слов).
- Классифицируем. Сначала пробуем простейшие линейные модели (например, логистическую регрессию, опорные вектора), смотрим на их качество, чтобы понять, с чем сравниваться. Затем переходим к более навороченным вариантам.
- Инспектируем.
**Нужно пытаться понять, как работает модель, интерпретировать её поведение.** Сделать это можно наблюдая за результатами классификации с помощью confusion matrix или списка топ-слов в каждой категории. 

Кроме того, в статье были рассмотрены предобученные нейронные сети, которые учитывают не просто частоту слов, но обрабатыват целые предложения (то есть уже умеют различать предложения “Alex eats plants” и “Plants eat Alex.”)
